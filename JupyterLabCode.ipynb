{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  Project 1 Group 7\n",
    "\n",
    " In this project we will evaluate CEO compensation, tenure, acceptance rate by board and shares owned by executives in order to predict stock prices for stocks belonging to the tech or financial sector \n",
    " Requirements: \n",
    " 1. Pandas to clean the data and format \n",
    " 2. Use jupyter notebook \n",
    "     with comments, good variable names, pseudocode \n",
    " 3. Jupyter notebook final charts \n",
    "     Use pyviz for plots and hvplot -- missing \n",
    "     Save images as png\n",
    " 4. Read me with the steps \n",
    " 5. Things we learned \n",
    " 6. Final conclusion \n",
    " 7. new API we cover and new python package we didnt cover \n",
    " 8. Keeping code tide \n",
    " \n",
    " We need to check this list.. This are from my class notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import panel as pn\n",
    "from panel.interact import interact\n",
    "from panel import widgets\n",
    "import matplotlib\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps.\n",
    "\n",
    "Files:\n",
    "1. approval_fin.csv\n",
    "2. approval_tech.csv\n",
    "3. comp_fin.csv\n",
    "4. comp_tech.csv\n",
    "5. mktcap_fin.csv\n",
    "6. mktcap_tech.csv\n",
    "7. price_fin.csv\n",
    "8. price_tech.csv\n",
    "9. sector_prices.csv\n",
    "10. sharesceo_fin.csv\n",
    "11. sharesceo_tech.csv\n",
    "12. tenure_fin.csv\n",
    "13. tenure_tech.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all the files we will create a data frame and clean - remove rows with NaN\n",
    "\n",
    "Please note that the dataframes are not from the same lenght "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Resources/approval_fin.csv' does not exist: b'Resources/approval_fin.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7fee2eda2556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reading approval rate of CEO for finanacial stocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemp_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resources/approval_fin.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata1_fin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata1_fin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1_fin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata1_fin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Resources/approval_fin.csv' does not exist: b'Resources/approval_fin.csv'"
     ]
    }
   ],
   "source": [
    "# Reading approval rate of CEO for finanacial stocks\n",
    "temp_csv = Path(\"Resources/approval_fin.csv\")\n",
    "data1_fin=pd.read_csv(temp_csv)\n",
    "data1_fin.set_index(pd.to_datetime(data1_fin['Date'], infer_datetime_format=True), inplace=True)\n",
    "data1_fin.drop(columns=['Date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1_fin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b3b444c6af36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Using new package to inspect the data and see how much missing data do we have.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Black represents there is a value, while white means that the data is missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmsno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1_fin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data1_fin' is not defined"
     ]
    }
   ],
   "source": [
    "#Using new package to inspect the data and see how much missing data do we have.\n",
    "#Black represents there is a value, while white means that the data is missing \n",
    "msno.matrix(data1_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with all NaN values \n",
    "data1_fin = data1_fin.dropna(how='all')\n",
    "data1_fin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading approval rate of CEO for technology stocks\n",
    "temp_csv = Path(\"Resources/approval_tech.csv\")\n",
    "data1_tech=pd.read_csv(temp_csv)\n",
    "data1_tech.set_index(pd.to_datetime(data1_tech['Date'], infer_datetime_format=True), inplace=True)\n",
    "data1_tech.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using new package to inspect the data and see how much missing data do we have.\n",
    "msno.matrix(data1_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with all NaN values \n",
    "data1_tech = data1_tech.dropna(how='all')\n",
    "data1_tech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading compensation rate of CEO for financial stocks\n",
    "temp_csv = Path(\"Resources/comp_fin.csv\")\n",
    "data2_fin=pd.read_csv(temp_csv)\n",
    "data2_fin.set_index(pd.to_datetime(data2_fin['Date'], infer_datetime_format=True), inplace=True)\n",
    "data2_fin.drop(columns=['Date'], inplace=True)\n",
    "#Scaling by million \n",
    "data2_fin=data2_fin/1000000\n",
    "data2_fin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading compensation rate of CEO for technology stocks\n",
    "temp_csv = Path(\"Resources/comp_tech.csv\")\n",
    "data2_tech=pd.read_csv(temp_csv)\n",
    "data2_tech.set_index(pd.to_datetime(data2_tech['Date'], infer_datetime_format=True), inplace=True)\n",
    "data2_tech.drop(columns=['Date'], inplace=True)\n",
    "#Scaling by million \n",
    "data2_tech=data2_tech/1000000\n",
    "data2_tech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading tenure of CEO for financials stocks - measure in years \n",
    "temp_csv = Path(\"Resources/tenure_fin.csv\")\n",
    "data3_fin=pd.read_csv(temp_csv)\n",
    "data3_fin.set_index(pd.to_datetime(data3_fin['Date'], infer_datetime_format=True), inplace=True)\n",
    "data3_fin.drop(columns=['Date'], inplace=True)\n",
    "data3_fin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading tenure of CEO for technology stocks - measure in years \n",
    "temp_csv = Path(\"Resources/tenure_tech.csv\")\n",
    "data3_tech=pd.read_csv(temp_csv)\n",
    "data3_tech.set_index(pd.to_datetime(data3_tech['Date'], infer_datetime_format=True), inplace=True)\n",
    "data3_tech.drop(columns=['Date'], inplace=True)\n",
    "data3_tech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading shares owned by ceo as % of shares outstanding for financial stocks\n",
    "temp_csv = Path(\"Resources/sharesceo_fin.csv\")\n",
    "data4_fin=pd.read_csv(temp_csv)\n",
    "data4_fin.set_index(pd.to_datetime(data4_fin['Date'], infer_datetime_format=True), inplace=True)\n",
    "data4_fin.drop(columns=['Date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using new package to inspect the data and see how much missing data do we have.\n",
    "msno.matrix(data4_fin)\n",
    "##only 4 years worth of data .. we need to analyze this data by year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with all NaN values \n",
    "data4_fin = data4_fin.dropna(how='all')\n",
    "data4_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading shares owned by ceo as % of shares outstanding for technology stocks\n",
    "temp_csv = Path(\"Resources/sharesceo_tech.csv\")\n",
    "data4_tech=pd.read_csv(temp_csv)\n",
    "data4_tech.set_index(pd.to_datetime(data4_tech['Date'], infer_datetime_format=True), inplace=True)\n",
    "data4_tech.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using new package to inspect the data and see how much missing data do we have.\n",
    "msno.matrix(data4_tech)\n",
    "##only 4 years worth of data .. we need to analyze this data by year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with all NaN values\n",
    "data4_tech = data4_tech.dropna(how='all')\n",
    "data4_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading price data for financial stocks\n",
    "temp_csv = Path(\"Resources/price_fin.csv\")\n",
    "price_fin=pd.read_csv(temp_csv)\n",
    "price_fin.set_index(pd.to_datetime(price_fin['Date'], infer_datetime_format=True), inplace=True)\n",
    "price_fin.drop(columns=['Date'], inplace=True)\n",
    "price_fin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non trading dates from the price data \n",
    "price_fin = price_fin.dropna(how='all')\n",
    "price_fin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading price data for technology stocks \n",
    "temp_csv = Path(\"Resources/price_tech.csv\")\n",
    "price_tech=pd.read_csv(temp_csv)\n",
    "price_tech.set_index(pd.to_datetime(price_tech['Date'], infer_datetime_format=True), inplace=True)\n",
    "price_tech.drop(columns=['Date'], inplace=True)\n",
    "price_tech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non trading dates from the price data \n",
    "price_tech = price_tech.dropna(how='all')\n",
    "price_tech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading market cap - financial stocks\n",
    "temp_csv = Path(\"Resources/mktcap_fin.csv\")\n",
    "mkt_cap_fin=pd.read_csv(temp_csv)\n",
    "mkt_cap_fin.set_index(pd.to_datetime(mkt_cap_fin['Date'], infer_datetime_format=True), inplace=True)\n",
    "mkt_cap_fin.drop(columns=['Date'], inplace=True)\n",
    "mkt_cap_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading market cap - technology stocks \n",
    "temp_csv = Path(\"Resources/mktcap_tech.csv\")\n",
    "mkt_cap_tech=pd.read_csv(temp_csv)\n",
    "mkt_cap_tech.set_index(pd.to_datetime(mkt_cap_tech['Date'], infer_datetime_format=True), inplace=True)\n",
    "mkt_cap_tech.drop(columns=['Date'], inplace=True)\n",
    "mkt_cap_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading prices for sector ETFs\n",
    "temp_csv = Path(\"Resources/sector_prices.csv\")\n",
    "price_sector=pd.read_csv(temp_csv)\n",
    "price_sector.set_index(pd.to_datetime(price_sector['Date'], infer_datetime_format=True), inplace=True)\n",
    "price_sector.drop(columns=['Date'], inplace=True)\n",
    "price_sector.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non trading dates from the price data \n",
    "price_sector = price_sector.dropna(how='all')\n",
    "price_sector.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating sector returns \n",
    "ret_sector = price_sector.pct_change()\n",
    "ret_sector = ret_sector.dropna(how='all')\n",
    "ret_sector.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating cumulative returns -\n",
    "cumulative_returns_sector = (1 + ret_sector).cumprod()\n",
    "cumulative_returns_sector.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using new package to inspect the data and see how much missing data do we have.\n",
    "msno.matrix(ret_sector) \n",
    "#XLRE missing the majority of the data -- this classification for real state is a new convention\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating cumulative returns by sector ETFs \n",
    "cumulative_returns_sector.hvplot.line( title='Sector ETFs and SP500', width=900, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on compensation metric \n",
    "# Box plot to visually see range of values per name\n",
    "data2_fin.hvplot.box(figsize=(25,15),rot=90,group_label='Financial Stocks', legend=False, value_label='Compensation', title='Dispersion on compensation metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on compensation metric \n",
    "# Box plot to visually see range of values per name\n",
    "data2_tech.hvplot.box(figsize=(25,15),rot=90,group_label='Tech Stocks', legend=False, value_label='Compensation', title='Dispersion on compensation metric')\n",
    "##Given that the distribution is tighter for tech we should expect finantial metrics to have more predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on tenure metric \n",
    "# Box plot to visually see range of values per name\n",
    "data3_fin.hvplot.box(figsize=(25,15),rot=90,group_label='Financial Stocks', legend=False, value_label='Tenure', title='Dispersion on tenure metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on tenure metric \n",
    "# Box plot to visually see range of values per name\n",
    "data3_tech.hvplot.box(figsize=(25,15),rot=90,group_label='Tech Stocks', legend=False, value_label='Tenure', title='Dispersion on tenure metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on approval metric \n",
    "# Box plot to visually see range of values per name\n",
    "data1_fin.hvplot.box(figsize=(25,15),rot=90,group_label='Financial Stocks', legend=False, value_label='Approval', title='Dispersion on approval metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on approval metric \n",
    "# Box plot to visually see range of values per name\n",
    "data1_tech.hvplot.box(figsize=(25,15),rot=90,group_label='Tech Stocks', legend=False, value_label='Approval', title='Dispersion on approval metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on share ownership metric \n",
    "# Box plot to visually see range of values per name\n",
    "data4_fin.hvplot.box(figsize=(25,15),rot=90,group_label='Financial Stocks', legend=False, value_label='Ownership', title='Dispersion on Ownership metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dispersion on share ownership metric \n",
    "# Box plot to visually see range of values per name\n",
    "data4_tech.hvplot.box(figsize=(25,15),rot=90,group_label='Tech Stocks', legend=False, value_label='Ownership', title='Dispersion on Ownership metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data frame with yearly prices \n",
    "#Finacial stocks \n",
    "price_fin.reset_index(inplace=True)\n",
    "price_fin.Date = pd.to_datetime(price_fin.Date)\n",
    "yearly_price_fin = price_fin.resample('Y', on='Date').last()\n",
    "yearly_price_fin.drop(columns=['Date'], inplace=True)\n",
    "yearly_price_fin.head()\n",
    "#Tech stocks \n",
    "price_tech.reset_index(inplace=True)\n",
    "price_tech.Date = pd.to_datetime(price_tech.Date)\n",
    "yearly_price_tech = price_tech.resample('Y', on='Date').last()\n",
    "yearly_price_tech.drop(columns=['Date'], inplace=True)\n",
    "yearly_price_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating yearly returns \n",
    "#Finanacial stocks \n",
    "ret_yearly_fin = yearly_price_fin.pct_change()\n",
    "ret_yearly_fin = ret_yearly_fin.dropna(how='all')\n",
    "ret_yearly_fin.head(3)\n",
    "#Tech Stocks \n",
    "ret_yearly_tech = yearly_price_tech.pct_change()\n",
    "ret_yearly_tech = ret_yearly_tech.dropna(how='all')\n",
    "ret_yearly_tech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation between CEO compensation and future yearly return\n",
    "#correlation analysis between compensation and yearly return - forward looking --  Financial Stocks\n",
    "\n",
    "df1=ret_yearly_fin.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "df2=data2_fin.reset_index()\n",
    "df2.drop(columns=['Date'], inplace=True)\n",
    "data_combined=df1.corrwith(df2, axis = 1, method= 'spearman' )\n",
    "mean_fin=data_combined.mean()\n",
    "mean_fin=pd.Series(mean_fin)\n",
    "mean_fin=pd.concat([mean_fin]*11, ignore_index=True)\n",
    "mean_fin.hvplot()\n",
    "new_df = pd.Series(range(2008,2019))\n",
    "\n",
    "mean_fin=pd.concat([new_df,mean_fin],axis=\"columns\", join=\"inner\")\n",
    "mean_fin.columns=['year','mean correlation']\n",
    "mean_fin.set_index('year', inplace=True)\n",
    "\n",
    "data_combined=pd.concat([new_df,data_combined],axis=\"columns\", join=\"inner\")\n",
    "data_combined.columns=['year','correlation']\n",
    "data_combined.set_index('year', inplace=True)\n",
    "data_combined.hvplot(x='year', y='correlation',kind='scatter',title='correlation between CEO compensation and future yearly return')* mean_fin.hvplot(line_color='red', line_width=0.5,ylim=(-0.5, 0.5))\n",
    "\n",
    "#horizontal line is the mean value over the period analyzed\n",
    "#WE can see that for financial stocks the correlation is almost 0 over time, it fluctuates some years positive, others negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation between CEO compensation and future yearly return\n",
    "#correlation analysis between compensation and yearly return - forward looking  Tech Stocks\n",
    "\n",
    "df1=ret_yearly_tech.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "df2=data2_tech.reset_index()\n",
    "df2.drop(columns=['Date'], inplace=True)\n",
    "data_combined=df1.corrwith(df2, axis = 1, method= 'spearman' )\n",
    "mean_fin=data_combined.mean()\n",
    "mean_fin=pd.Series(mean_fin)\n",
    "mean_fin=pd.concat([mean_fin]*11, ignore_index=True)\n",
    "mean_fin.hvplot()\n",
    "new_df = pd.Series(range(2008,2019))\n",
    "\n",
    "mean_fin=pd.concat([new_df,mean_fin],axis=\"columns\", join=\"inner\")\n",
    "mean_fin.columns=['year','mean correlation']\n",
    "mean_fin.set_index('year', inplace=True)\n",
    "\n",
    "data_combined=pd.concat([new_df,data_combined],axis=\"columns\", join=\"inner\")\n",
    "data_combined.columns=['year','correlation']\n",
    "data_combined.set_index('year', inplace=True)\n",
    "data_combined.hvplot(x='year', y='correlation',kind='scatter',title='correlation between CEO compensation and future yearly return')* mean_fin.hvplot(line_color='red', line_width=0.5,ylim=(-0.5, 0.5))\n",
    "\n",
    "#horizontal line is the mean value over the period analyzed\n",
    "#WE can see that for tech stocks the correlation is negative over time, the more compensation the CEO gets the worst the stock performs in later years \n",
    "#Correlation is subtle .. not that high though. overall CEO comp is negatively correlated with future performance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis between tenure and yearly return - forward looking -- Financial Stocks\n",
    "df1=ret_yearly_fin.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "df2=data3_fin.reset_index()\n",
    "df2.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "data_combined=df1.corrwith(df2, axis = 1, method= 'spearman' )\n",
    "mean_fin=data_combined.mean()\n",
    "mean_fin=pd.Series(mean_fin)\n",
    "mean_fin=pd.concat([mean_fin]*11, ignore_index=True)\n",
    "mean_fin.hvplot()\n",
    "new_df = pd.Series(range(2008,2019))\n",
    "\n",
    "mean_fin=pd.concat([new_df,mean_fin],axis=\"columns\", join=\"inner\")\n",
    "mean_fin.columns=['year','mean correlation']\n",
    "mean_fin.set_index('year', inplace=True)\n",
    "\n",
    "data_combined=pd.concat([new_df,data_combined],axis=\"columns\", join=\"inner\")\n",
    "data_combined.columns=['year','correlation']\n",
    "data_combined.set_index('year', inplace=True)\n",
    "data_combined.hvplot(x='year', y='correlation',kind='scatter',title='correlation between CEO tenure and future yearly return')* mean_fin.hvplot(line_color='red', line_width=0.5,ylim=(-0.5, 0.5))\n",
    "\n",
    "#horizontal line is the mean value over the period analyzed\n",
    "#WE can see that for financial stocks the correlation is slightly positive over time, very small though, we need more data to validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis between tenure and yearly return - forward looking -- need to add dates \n",
    "df1=ret_yearly_tech.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "df2=data3_tech.reset_index()\n",
    "df2.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "data_combined=df1.corrwith(df2, axis = 1, method= 'spearman' )\n",
    "mean_fin=data_combined.mean()\n",
    "mean_fin=pd.Series(mean_fin)\n",
    "mean_fin=pd.concat([mean_fin]*11, ignore_index=True)\n",
    "mean_fin.hvplot()\n",
    "new_df = pd.Series(range(2008,2019))\n",
    "\n",
    "mean_fin=pd.concat([new_df,mean_fin],axis=\"columns\", join=\"inner\")\n",
    "mean_fin.columns=['year','mean correlation']\n",
    "mean_fin.set_index('year', inplace=True)\n",
    "\n",
    "data_combined=pd.concat([new_df,data_combined],axis=\"columns\", join=\"inner\")\n",
    "data_combined.columns=['year','correlation']\n",
    "data_combined.set_index('year', inplace=True)\n",
    "data_combined.hvplot(x='year', y='correlation',kind='scatter',title='correlation between CEO tenure and future yearly return')* mean_fin.hvplot(line_color='red', line_width=0.5,ylim=(-0.5, 0.5))\n",
    "\n",
    "#horizontal line is the mean value over the period analyzed\n",
    "#WE can see that for tech stocks the correlation is slightly positive over time. which means that if the CEO remains in the company \n",
    "#for a long period of time that is a good indication of future stock performance, while if there is a lot of turnover that is an \n",
    "#indication of stock underperformance in the future\n",
    "#Tech stocks exhibit clearer pattern than financial stocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!\n",
    "#Creating scatter plots for shares owned by ceo as % of shares outstanding for financial stocks and yearly return\n",
    "df1=ret_yearly_fin.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "pn.extension()\n",
    "\n",
    "new_index= ['2015', '2016', '2017','2018']\n",
    "\n",
    "def rel_ownership_year(year):\n",
    "    if year=='2015':\n",
    "        \n",
    "        datay2=pd.concat([df1.iloc[8],data4_fin.iloc[0]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "  \n",
    "    elif year=='2016':\n",
    "        datay2=pd.concat([df1.iloc[9],data4_fin.iloc[1]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "        \n",
    "    elif year=='2017':\n",
    "        datay2=pd.concat([df1.iloc[10],data4_fin.iloc[2]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "    \n",
    "    else:\n",
    "        datay2=pd.concat([df1.iloc[11],data4_fin.iloc[3]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "\n",
    "    return datay2.hvplot( kind='scatter',x='yearly_ret', y='shares',title='Relationship between shares owned by CEO and Future yearly return',xlim=(-1, 1),ylim=(0, 10))\n",
    "\n",
    "interact(rel_ownership_year, year=new_index)\n",
    "\n",
    "#The hypothesis we are trying to solve with this data is that we think that when there is more at stake for the CEO -financialy- \n",
    "#the more he/she be concern on managing well the company. it is midly confirm with the data. There is very little dispersion on the \n",
    "#metric.. CEOs own similar % for the majority of the stocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating scatter plots for shares owned by ceo as % of shares outstanding for technology stocks and yearly return\n",
    "df1=ret_yearly_tech.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "pn.extension()\n",
    "\n",
    "new_index= ['2015', '2016', '2017','2018']\n",
    "\n",
    "def rel_ownership_year_tech(year):\n",
    "    if year=='2015':\n",
    "        \n",
    "        datay2=pd.concat([df1.iloc[8],data4_tech.iloc[0]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "  \n",
    "    elif year=='2016':\n",
    "        datay2=pd.concat([df1.iloc[9],data4_tech.iloc[1]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "        \n",
    "    elif year=='2017':\n",
    "        datay2=pd.concat([df1.iloc[10],data4_tech.iloc[2]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "    \n",
    "    else:\n",
    "        datay2=pd.concat([df1.iloc[11],data4_tech.iloc[3]],axis=\"columns\", join=\"inner\")\n",
    "        datay2.columns=['yearly_ret','shares']\n",
    "\n",
    "    return datay2.hvplot( kind='scatter',x='yearly_ret', y='shares',title='Relationship between shares owned by CEO and Future yearly return',xlim=(-1, 1),ylim=(0, 10))\n",
    "\n",
    "interact(rel_ownership_year_tech, year=new_index)\n",
    "\n",
    "#The hypothesis we are trying to solve with this data is that we think that when there is more at stake for the CEO -financialy- \n",
    "#the more he/she be concern on managing well the company. it is midly confirm with the data. There is very little dispersion on the \n",
    "#metric.. CEOs own similar % for the majority of the stocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis between approval and yearly return - forward looking \n",
    "df1=ret_yearly_fin.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "df1.drop(df1.index[[0,1,2]],inplace=True)\n",
    "df1=df1.reset_index()\n",
    "df1.drop(columns=['index'], inplace=True)\n",
    "df2=data1_fin.reset_index()\n",
    "df2.drop(columns=['Date'], inplace=True)\n",
    "df2.drop(df2.index[[0]],inplace=True)\n",
    "df2=df2.reset_index()\n",
    "df2.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "data_combined=df1.corrwith(df2, axis = 1, method= 'spearman' )\n",
    "mean_fin=data_combined.mean()\n",
    "mean_fin=pd.Series(mean_fin)\n",
    "mean_fin=pd.concat([mean_fin]*11, ignore_index=True)\n",
    "mean_fin.hvplot()\n",
    "new_df = pd.Series(range(2010,2020))\n",
    "\n",
    "mean_fin=pd.concat([new_df,mean_fin],axis=\"columns\", join=\"inner\")\n",
    "mean_fin.columns=['year','mean correlation']\n",
    "mean_fin.set_index('year', inplace=True)\n",
    "\n",
    "data_combined=pd.concat([new_df,data_combined],axis=\"columns\", join=\"inner\")\n",
    "data_combined.columns=['year','correlation']\n",
    "data_combined.set_index('year', inplace=True)\n",
    "data_combined.hvplot(x='year', y='correlation',kind='scatter',title='correlation between CEO approval and future yearly return')* mean_fin.hvplot(line_color='red', line_width=0.5,ylim=(-0.5, 0.5))\n",
    "\n",
    "#horizontal line is the mean value over the period analyzed\n",
    "#WE can see that for financial stocks it does not appear that there is a relationship between approval and future performance \n",
    "#Correlation 0 over time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis between approval and yearly return - forward looking -- need to add dates \n",
    "df1=ret_yearly_tech.reset_index()\n",
    "df1.drop(columns=['Date'], inplace=True)\n",
    "df1.drop(df1.index[[0,1,2]],inplace=True)\n",
    "df1=df1.reset_index()\n",
    "df1.drop(columns=['index'], inplace=True)\n",
    "df2=data1_tech.reset_index()\n",
    "df2.drop(columns=['Date'], inplace=True)\n",
    "df2.drop(df2.index[[0]],inplace=True)\n",
    "df2=df2.reset_index()\n",
    "df2.drop(columns=['index'], inplace=True)\n",
    "\n",
    "data_combined=df1.corrwith(df2, axis = 1, method= 'spearman' )\n",
    "mean_fin=data_combined.mean()\n",
    "mean_fin=pd.Series(mean_fin)\n",
    "mean_fin=pd.concat([mean_fin]*11, ignore_index=True)\n",
    "mean_fin.hvplot()\n",
    "new_df = pd.Series(range(2010,2020))\n",
    "\n",
    "mean_fin=pd.concat([new_df,mean_fin],axis=\"columns\", join=\"inner\")\n",
    "mean_fin.columns=['year','mean correlation']\n",
    "mean_fin.set_index('year', inplace=True)\n",
    "\n",
    "data_combined=pd.concat([new_df,data_combined],axis=\"columns\", join=\"inner\")\n",
    "data_combined.columns=['year','correlation']\n",
    "data_combined.set_index('year', inplace=True)\n",
    "data_combined.hvplot(x='year', y='correlation',kind='scatter',title='correlation between CEO approval and future yearly return')* mean_fin.hvplot(line_color='red', line_width=0.5,ylim=(-0.5, 0.5))\n",
    "\n",
    "#horizontal line is the mean value over the period analyzed\n",
    "#WE can see that for tech stocks the correlation is positive over time. which means that if the CEO is widely approved by the board\n",
    "#that is a good indication of stock outperfomance in the future \n",
    "#Tech pattern is more clear than financial stocks but confirms intuition where the more approval the better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract selecting year 2015 for tech stocks and visually see interactions \n",
    "#Compensation, approval, tenure\n",
    "#We are calculating rank on each metric and we want to see the extreme values relationship given that \n",
    "#the correlation are low on the 3 metrics \n",
    "\n",
    "data_combined3=pd.concat([ret_yearly_tech.iloc[8],data2_tech.iloc[8],data1_tech.iloc[6],data3_tech.iloc[8]],axis=\"columns\", join=\"inner\")\n",
    "data_combined3.columns=['Future_ret','compensation','approval','tenure']\n",
    "data_combined3.dropna(inplace=True)\n",
    "data_combined3=data_combined3.sort_values(by=['Future_ret'],ascending=False)\n",
    "data_combined3[\"Rank_FutRet\"] = data_combined3[\"Future_ret\"].rank(ascending=False)\n",
    "data_combined3[\"Rank_Compompensation\"] = data_combined3[\"compensation\"].rank(ascending=False) \n",
    "data_combined3[\"Rank_Approval\"] = data_combined3[\"approval\"].rank(ascending=False) \n",
    "data_combined3[\"Rank_Tenure\"] = data_combined3[\"tenure\"].rank(ascending=False) \n",
    "data_combined3.drop(columns=['Future_ret','compensation','approval','tenure'], inplace=True)\n",
    "data_combined3=data_combined3.drop(data_combined3.index[15:46])\n",
    "\n",
    "\n",
    "fig=px.parallel_coordinates(data_combined3, color='Rank_FutRet')\n",
    "fig.show()\n",
    "\n",
    "#very hard to see from the plot itself, but this plot was a requirement on the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "0.12.3"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
